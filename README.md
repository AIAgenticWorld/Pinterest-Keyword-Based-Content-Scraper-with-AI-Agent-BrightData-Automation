<img width="710" height="386" alt="image" src="https://github.com/user-attachments/assets/0d50bfba-e28f-471d-bc0b-ec4e4762ccce" />

# ğŸ§² Pinterest Scraper Workflow (AI-Powered)

This is an automated Pinterest scraping pipeline powered by Claude Sonnet 4 and BrightData, with results stored in Google Sheets. Designed for efficiency, the workflow is triggered by keyword input and fully managed by AI and automation components.

---

## ğŸ§  Architecture Components

### AI-Powered Controller
- **Claude Sonnet 4**: Processes and understands search keywords before initiating scrape
- **AI Agent**: Orchestrates and monitors the scraping process end-to-end

### ğŸ“¥ Data Input
- **Form Trigger**: Clean interface for keyword submission
- **Keywords Field**: Required field for Pinterest search terms

### ğŸš€ Scraping Pipeline
1. **Launch Scraping Job**: Sends keywords to BrightData API
2. **Status Monitoring**: Tracks scraping job progress
3. **Data Retrieval**: Downloads scraped data
4. **Data Processing**: Extracts and formats Pinterest content
5. **Google Sheets Storage**: Appends structured results

---

## ğŸ”§ Workflow Nodes

### 1. ğŸ“ Pinterest Keyword Input
- **Type**: Form Trigger
- **Title**: "Pinterest"
- **Field**: `Keywords` (required)

### 2. ğŸ§  Claude Sonnet 4
- **Type**: Language Model
- **Model**: `claude-sonnet-4-20250514`
- **Purpose**: Processes keywords and manages scraping logic

### 3. ğŸ¤– Keyword-Based Scraping Agent
- **Type**: AI Agent
- **Instructions**:
  - Start BrightData scraping with keywords
  - Monitor progress
  - Retrieve and return raw data

### 4. ğŸ”— BrightData Scraping Job
- **Type**: HTTP Request (POST)
- **Endpoint**: `https://api.brightdata.com/datasets/v3/trigger`
- **Parameters**:
  - `dataset_id`: `gd_lk0sjs4d21kdr7cnlv`
  - `type`: `discover_new`
  - `discover_by`: `keyword`
  - `limit_per_input`: `2`
  - `include_errors`: `true`

### 5. â³ Check Scraping Status
- **Type**: HTTP Request (GET)
- **Endpoint**: `https://api.brightdata.com/datasets/v3/progress/{snapshot_id}`
- **Checks for**: `running`, `ready`

### 6. ğŸ“¥ Fetch Pinterest Snapshot Data
- **Type**: HTTP Request (GET)
- **Endpoint**: `https://api.brightdata.com/datasets/v3/snapshot/{snapshot_id}`
- **Triggers**: When status is `ready`

### 7. ğŸ›  Format & Extract Pinterest Content
- **Type**: JavaScript Code Node
- **Extracted Fields**:
  - `URL`
  - `Post ID`
  - `Title`
  - `Content`
  - `Date Posted`
  - `User`
  - `Likes & Comments`
  - `Media`
  - `Image URL`
  - `Categories`
  - `Hashtags`

### 8. ğŸ“Š Save Data to Google Sheets
- **Type**: Google Sheets Node
- **Operation**: Append rows
- **Mapped Columns**:
  - `Post URL`
  - `Title`
  - `Content`
  - `Image URL`

### 9. â± (Optional) Wait Node
- **Purpose**: Adds a 60-second delay between status checks
- **Status**: Disabled by default

---

## âš™ï¸ Setup Instructions

### ğŸ” Required Credentials
- **Anthropic API**
  - Credential ID: `ANTHROPIC_CREDENTIAL_ID`
- **BrightData API**
  - API Key: `BRIGHT_DATA_API_KEY`
- **Google Sheets OAuth2**
  - Credential ID: `GOOGLE_SHEETS_CREDENTIAL_ID`

### ğŸ§© Replace Placeholders
Ensure you update the following in your workflow:
- `WEBHOOK_ID_PLACEHOLDER`
- `GOOGLE_SHEET_ID_PLACEHOLDER`
- `WORKFLOW_ID_PLACEHOLDER`
- `WORKFLOW_VERSION_ID`
- `INSTANCE_ID_PLACEHOLDER`

---

## ğŸ§ª How to Use

### âœ… Initial Setup
1. Configure all credentials in n8n
2. Replace placeholder values
3. Set up your Google Sheet using the [template](https://docs.google.com/spreadsheets/d/SAMPLE_SHEET_ID/edit)

### â–¶ï¸ Run the Workflow
1. Access the form trigger URL
2. Enter Pinterest keywords
3. Submit to begin scraping

### ğŸ” Monitoring
- AI agent handles scraping status checks automatically

### ğŸ“ Accessing Results
- Scraped content is appended to your linked Google Sheets document

---

## ğŸ“¦ Output Data Structure

Each Pinterest post will include:
| Field          | Description                         |
|----------------|-------------------------------------|
| `URL`          | Direct link to the pin              |
| `Post ID`      | Unique identifier                   |
| `Title`        | Pin title                           |
| `Content`      | Pin description                     |
| `Date Posted`  | Publication date                    |
| `User`         | Username                            |
| `Likes & Comments` | Engagement details              |
| `Media`        | Media type                          |
| `Image URL`    | Direct image link                   |
| `Categories`   | Tags/categories                     |
| `Hashtags`     | Associated hashtags                 |
| `Comments`     | Comment text (if available)         |

---

## ğŸ”§ Customization Options

- **ğŸ“Œ Adjust Data Volume**: Change `limit_per_input` in scraping node
- **â² Enable Delay**: Activate the wait node for long scraping sessions
- **ğŸ›  Extract More Data**: Modify the JavaScript formatting node
- **ğŸ—ƒ Change Storage**: Replace Google Sheets with any storage tool

---

## ğŸ“‹ Sample Google Sheet Template

Use this template as a base:
ğŸ‘‰ [Google Sheet Template](https://docs.google.com/spreadsheets/d/SAMPLE_SHEET_ID/edit)

**Required Columns:**
- `Post URL`
- `Title`
- `Content`
- `Image URL`

---

## ğŸ“ Notes

- BrightData API has rate limits
- Scraping currently limited to **2 pins per keyword**
- Supports async scraping and polling
- Error handling included for scraping steps

---

## ğŸ“£ Support

For issues, questions, or ideas â€” open a discussion or submit a pull request ğŸ’¬

---

**Happy Scraping!** ğŸ§©ğŸ“ŒğŸ“Š
